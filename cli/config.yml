path: ..
include:
  - '**/*.ts'
exclude:
  - '**/node_modules/**'
  - '**/dist/**'
logLevel: error # error| info | warn | error | debug | silly
llmProvider: ollama

## Individual providers and models can be configured here
# llms:
#   agent:
#     provider: ollama
#     model: mixtral:8x7b
#   embedding:
#     provider: ollama
#     model: nomic-embed-text
#   summarize:
#     provider: ollama
#     model: mixtral:8x7b
#   tool:
#     provider: ollama
#     model: mixtral:8x7b

providers:
  openai:
    apiKey: ''
  ollama:
    host: 'http://localhost:11434'
