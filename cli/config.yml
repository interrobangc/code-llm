project:
  name: 'codellm'

paths:
  project: ..
  cache: ../.cache

logLevel: info # error| info | warn | error | debug | silly

# The default provider to use for all commands
llmProvider: ollama # openai | ollama

# The format to use for the output of LLM messages so that the agent can understand it
# is sent to the LLM in the initial system message and all subsequent user messages
# when formatInUserMessage is true. This helps less powerful LLMs to "remember" how to
# format the output for the user. If you are using a more powerful LLM and paying for
# message tokens, you can set this to false and the agent will only send the format to
# the LLM in the initial system message which will save you tokens and processing time.
formatInUserMessage: false

tools:
  codeElementsQuery:
    module: '@codellm/tool-code-elements-query'
    config:
      vectorDbName: chromadb
      vectorDbCollectionName: codeElements
  codeSummaryQuery:
    module: '@codellm/tool-code-summary-query'
    config:
      vectorDbName: chromadb
      vectorDbCollectionName: codeSummary
  # docSummaryQuery:
  #   module: '@codellm/tool-doc-summary-query'
  #   config:
  #     vectorDbName: chromadb
  #     vectorDbCollectionName: docSummary
  fileReader:
    module: '@codellm/tool-file-reader'
    config:
      maxFileCount: 8
  # jsDependencyTree:
  #   module: '@codellm/tool-js-dependency-tree'
  projectGlob:
    module: '@codellm/tool-project-glob'

# The configuration for individual providers can be set here. You probably want to use
# the OPEN_AI_API_KEY or MISTRAL_API_KEY environment variable instead of hardcoding your key here
providers:
  mistral:
    config:
      apiKey: ''

  openai:
    config:
      apiKey: ''

  ollama:
    config:
      host: 'http://localhost:11434'
## Individual providers and models for various parts of the system can be configured here
## Available Ollama models can be found here: https://ollama.com/library/
## Available Openai models can be found here: https://platform.openai.com/account/limits
# llms:
#   agent:
#     provider: ollama
#     model: mixtral:8x7b
#   embedding:
#     provider: ollama
#     model: nomic-embed-text
#   summarize:
#     provider: ollama
#     model: mixtral:8x7b
#   tool:
#     provider: ollama
#     model: mixtral:8x7b

